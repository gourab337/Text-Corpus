'''তত্ত্বাবধানে জ্ঞান অর্জন''' () হল প্রদত্ত উপাত্ত এবং তার ফলাফল থেকে যান্ত্রিক জ্ঞানার্জন প্রক্রিয়া, যা সংজ্ঞায়িত উপাত্ত সমূহ থেকে একটি ফাংশন খুঁজে নেয়। তত্ত্বাবধীন জ্ঞানার্জনে প্রত্যেকটি তথ্য হলো একেকটি জোড়া, যাতে একটি ইনপুট উপাত্ত (যা সাধারণত একটি ভেক্টর) এবং প্রত্যাশিত ফলাফল উপাত্ত সংকেত'''ও বলা হয়) থাকে। একটি সুপারভাইজ লার্নিং অ্যালগরিদম প্রদত্ত উপাত্ত গুলোকে বিশ্লেষণ করে এবং একটি ফাংশন তৈরি করে নতুন উপাত্তকে সংজ্ঞায়িত করতে সহায়তা করে। উপযুক্ত ক্ষেত্রে আলগরিদমটি নতুন কোন বস্তু ('''Object''') কে সঠিকভাবে শ্রেণীকরণে ভূমিকা রাখতে পারে। এক্ষেত্রে এটি যৌক্তিকভাবে প্রদত্ত উপাত্তের সাথে নতুন উপাত্তের সাধারণ সম্পর্ক ('''Mapping''') তৈরি করে। মানুষ এবং প্রাণী এটিকে প্রায়ই '''কনসেপ্ট লার্নিং''' হিসেবে উল্লেখ করা হয়। == ধাপসমূহ == শিরোনাম শনাক্তকরণের জন্য Supervised লার্নিং'' এর কোন সমস্যা সমাধান করতে হলে একজন ব্যক্তিকে অবশ্যই নিম্নোক্ত ধাপসমূহ সম্পন্ন করতে হবে: '''প্রদত্ত উপাত্তের ধরন যাচাইকরণঃ''' অন্য কোন কিছু করার পূর্বে ব্যবহারকারীকে অবশ্যই সিদ্ধান্ত নিতে হবে যে, কোন কোন উপাত্ত ব্যবহার করা হবে। উদাহরণস্বরূপ, হস্তলিপি বিশ্লেষণের ক্ষেত্রে এটি হতে পারে একটি হাতে লেখা বর্ণ, একটি শব্দ কিংবা একটি সম্পূর্ণ বাক্য। '''উপাত্ত সংগ্রহ করণঃ''' উপাত্ত গুলো অবশ্যই বাস্তব জীবনে ফাংশনটির প্রয়োগের প্রতিনিধিত্ব করতে হবে। এভাবে বিশেষজ্ঞ ব্যক্তি কিংবা পরিমাপের দ্বারা অনেকগুলো ইনপুট উপাত্ত এবং সংশ্লিষ্ট ফলাফল উপাত্ত ('''Output Data''') সংগ্রহ করা হয়। '''প্রদত্ত উপাত্ত গুলোর বৈশিষ্ট্য ('''Feature''') নিরূপণঃ''' অর্জিত ফাংশনটির নির্ভুলতা নির্ভর করে কিভাবে ইনপুট উপাত্তটির বৈশিষ্ট্য ('''Feature''') নিরূপণ করা হয়েছে। অর্থাৎ ইনপুট উপাত্ত টি একটি বৈশিষ্ট্য ভেক্টর রুপান্তর করা, হয় যাতে উক্ত ইনপুট বস্তুটির কিছু সাংখিক বৈশিষ্ট্য থাকে। মাত্রিক সীমাবদ্ধতার কারণে বৈশিষ্ট্যের সংখ্যা খুব বেশি হওয়া উচিত নয় কিন্তু ফলাফল অনুমান ('''Predict''') করার জন্য যথেষ্ট সংখ্যক বৈশিষ্ট্য থাকা প্রয়োজন। '''অর্জিত ফাংশনের গঠন এবং সংশ্লিষ্ট জ্ঞানার্জন অ্যালগরিদম নির্বাচনঃ''' ইঞ্জিনিয়ার সাপোর্ট ভেক্টর মেশিন অথবা শাখান্বিত সিদ্ধান্ত পদ্ধতি অবলম্বন করতে পারেন। '''পরিকল্পনা উপলব্ধ উপাত্ত সমূহ অ্যালগরিদম প্রয়োগ করুন। কিছু অ্যালগরিদম এর ক্ষেত্রে নির্দিষ্ট সংখ্যক নির্ধারক পরামিতি প্রয়োজন হয়। এই পরামিতিগুলো যাচাইকরণ সেটের ('''Validation Set''') অনুকুল পারফরম্যান্সের উপর ভিত্তি করে নির্ধারণ করা হয়। '''অর্জিত ফাংশনের নির্ভুলতা যাচাইঃ''' পরামিতি সমন্বয় এবং শিক্ষণের পর পরীক্ষামূলক সেটে ('''Test set''') প্রাপ্ত ফাংশনের নির্ভুলতা মূল্যায়ন করা হয়। == অ্যালগরিদম নির্বাচন== অনেকগুলো সুপারভাইজ লার্নিং অ্যালগরিদম রয়েছে যার প্রত্যেকের রয়েছে নিজস্ব সফলতা এবং সীমাবদ্ধতা। সুপারভাইজ লার্নিং এর সর্বোত্তম ফলাফল দেয় এমন কোন অ্যালগরিদম এখন পর্যন্ত নেই। সুপারভাইজ লার্নিং নিয়ে মূলত চারটি প্রধান বিষয় বিবেচনা করা হয় === ধ্রুবক ভেদাঙ্কের পার্থক্য === প্রথম বিষয়টি হল ধ্রুবক ('''Bias''') এবং ভেদাঙ্কের মাঝে সমন্বয়। মনে করুন যে, আমাদের কাছে কিছু ভিন্ন ভিন্ন কিন্তু মোটামুটি সমমানের উপাত্ত সেট রয়েছে। যদি একটি উপাত্ত এর জন্য অর্জিত ফাংশনে কোনো ধ্রুবক থাকে, তবে এসব উপাত্তগুলো দ্বারা প্রশিক্ষণ দেয়া হলে, স্বাভাবিকভাবেই এর ফলাফল প্রদান করার সময় এটি ভুল করবে। যদি বিভিন্ন উপাত্ত এর উপর প্রশিক্ষণ করার সময় বিভিন্ন ফলাফল প্রদান করে তবে ধরা হয় যে উপাত্তটির জন্য এর ব্যাপক ভেদাঙ্ক রয়েছে। এক্ষেত্রে অনুমানের ভুলের পরিমাণ ধ্রুবক এবং ভেদাঙ্কের সমষ্টির সঙ্গে সম্পর্কিত। সাধারণভাবে ধ্রুবক এবং ভেদাঙ্কের মাঝে এক প্রকারের সমন্বয় থাকে। নিম্ন ধ্রুবকবিশিষ্ট কোন লার্নিং অ্যালগরিদম অবশ্যই উপাত্ত সংগ্রহের সঙ্গে মানানসই হওয়ার মতো নমনীয়তা ধারণ করতে হবে। কিন্তু যদি লার্নিং অ্যালগরিদম টি খুব বেশি নমনীয় হয়, তবে এটি প্রত্যেকটি উপাত্তের সঙ্গে মানিয়ে নেবে এবং এতে ব্যাপক ভেদাঙ্ক দেখা যাবে। সুতরাং সুপারভাইজ লার্নিং পদ্ধতিতে এই ধ্রুবক এবং ভেদাঙ্কসমূহ কিংবা ব্যবহারকারী কর্তৃক নির্ধারিত করে দিতে হয়। === ফাংশন এর জটিলতা এবং প্রশিক্ষণ উপাত্তের পরিমাণ === দ্বিতীয় বিষয়টি হলো প্রকৃত ফাংশনটির জটিলতার সাপেক্ষে প্রশিক্ষণ উপাত্তের পরিমাণ। যদি প্রকৃত ফাংশনটি সরল আকারের হয়, তবে উচ্চ ধ্রুবক এবং নিম্ন ভেদাঙ্কবিশিষ্ট '''অনমনীয়''' প্রশিক্ষণ অ্যালগরিদম সামান্য পরিমাণ উপাত্ত থেকে প্রশিক্ষণ নিতে পারে। কিন্তু যদি প্রকৃত ফাংশনটি ব্যাপক জটিল হয় তবে এটি শুধুমাত্র নিম্ন ধ্রুবক এবং উচ্চ ভেদাঙ্কবিশিষ্ট '''নমনীয়''' প্রশিক্ষণ আলগরিদম থেকেই প্রশিক্ষণ নিতে পারে। === ইনপুট ক্ষেত্রের মাত্রিকতা === তৃতীয় বিষয়টি হলো ইনপুট ক্ষেত্রের মাত্রিকতা। যদি ইনপুট বৈশিষ্ট্য ভেক্টর এর মাত্রা ব্যাপক বড় হয় তবে, যদিও প্রকৃত ফাংশন সামান্য কিছু বৈশিষ্ট্যের উপর নির্ভর করে, প্রশিক্ষণের সমস্যাটি প্রচুর কঠিন হয়ে যায়। কারণ, এক্ষেত্রে বাড়তি মাত্রা গুলো প্রশিক্ষণ অ্যালগরিদমটিকে বিভ্রান্ত করে দেবে এবং উচ্চ ভেদাঙ্ক আনতে বাধ্য করবে। তাই শুধুমাত্র প্রয়োজনীয় বৈশিষ্ট্য গুলো নির্বাচন করা উচিত। প্রয়োজনীয় বৈশিষ্ট্য নির্বাচন এর জন্য বিভিন্ন অ্যালগরিদম রয়েছে। এগুলো মূলত মাত্রিকতা হ্রাসের একটি সাধারণ রূপ। === ফলাফলে অবাঞ্ছিত মান === চতুর্থ বিষয়টি হলো ফলাফল অবাঞ্ছিত মান ('''Noise''') এর মাত্রা। মানুষ কিংবা সেন্সরের কারনে যদি প্রত্যাশিত ফলাফল প্রায়ই ভুল হয়, তবে প্রশিক্ষণ অ্যালগরিদমটি প্রদত্ত উপাত্তগুলোর সঙ্গে যথার্থভাবে মিলে যায় এমন কোন ফাংশন খুঁজে পাবে না। ফলে উপাত্ত গুলোর সঙ্গে মানানসই ('''Fit''') হওয়ার জন্য ফাংশন খুঁজতে গিয়ে প্রশিক্ষণ অ্যালগরিদমটি দিকে ধাবিত হয়। আপনার প্রশিক্ষণ মডেলের ফাংশনটি যদি ব্যাপক জটিল হয় তবে আপনি অতিমান্যতার দিকে ধাবিত হতে পারেন, এমনকি যদি কোন পরিমাপ ত্রুটি নাও হয় তবুও। এই পরিস্থিতিতে প্রত্যাশিত ফাংশনের যে অংশটি সাধারণীকরণ করা যায় না, তা আপনার উপাত্তসমূহকে বিক্ষিপ্ত করে দেয় যাকে বলা হয় অবাঞ্ছিত noise''')। যদি কোন একধরনের অবাঞ্ছিত মান বিদ্যমান থাকে তবে নিম্ন ভেদাঙ্ক এবং উচ্চ ধ্রুবকসমৃদ্ধ ফাংশন তুলনামূলক ভালো পারর্ফমেন্স দেয়। বাস্তবিক ক্ষেত্রে অবাঞ্ছিত মানসমূহ প্রত্যাহার করার জন্য কিছু উপায় রয়েছে, যেমন অতিমান্যতাকে রোধ করার জন্য stopping''') এর পাশাপাশি অস্বাভাবিকতা সনাক্তকরণ এবং প্রশিক্ষণ চলাকালীন অবাঞ্ছিত প্রশিক্ষণ উপাত্ত অপসারণ। === অন্যান্য প্রয়োজনীয় বিবেচ্য বিষয় === প্রশিক্ষণ অ্যালগরিদম নির্বাচন এবং প্রয়োগের জন্য অন্যান্য যেসব বিষয় বিবেচনা করা হয় তা নিম্নরূপ '''উপাত্তের বিভিন্নতা:''' যদি বৈশিষ্ট্য ভেক্টর বিভিন্ন প্রকারের বৈশিষ্ট্য (বিচ্ছিন্ন, ক্রম বিচ্ছিন্ন, অবিচ্ছিন্ন মান) বিদ্যমান থাকে, তবে কিছু কিছু অ্যালগরিদম বাস্তবায়ন করা তুলনামূলকভাবে সহজ হয় সাপোর্ট ভেক্টর মেশিন, লিনিয়ার রিগ্রেশন, লজিস্টিক রিগ্রেশন কৃত্রিম নিউরাল নেটওয়ার্ক এবং K-তম নিকটবর্তী প্রতিবেশী অ্যালগোরিদমের মতো অনেক অ্যালগরিদমের ক্ষেত্রে সকল বৈশিষ্ট্য সম পরিসরে (অর্থাৎ -1,1 ব্যবধিতে) হতে হয়। বিশেষ করে K-তম নিকটবর্তী প্রতিবেশী অ্যালগরিদম এবং সাপোর্ট ভেক্টর মেশিন ব্যাপারে অতি সংবেদনশীল। সিদ্ধান্ত বৃক্ষের একটি সুবিধা হলো যে, এটি সহজে বিভিন্ন ধরনের উপাত্তকে ব্যবস্থাপনা করতে পারেন। '''উপাত্তের পুনরাবৃত্তি:''' যদি ইনপুট বৈশিষ্ট্যে পুনরাবৃত্তিমূলক কিংবা ব্যাপকভাবে সম্পর্কিত বৈশিষ্ট্য থাকে, তবে লিনিয়ার রিগ্রেশন, লজিস্টিক রিগ্রেশন এবং কে তম নিকটবর্তী প্রতিবেশী অ্যালগরিদম সাংখ্যিক অস্থিতিশীলতার কারণে বাজে পারফরম্যান্স করে। নিয়মিতকরণের মাধ্যমে এসব সমস্যা থেকে উত্তরণে হওয়া যায়। '''মিথস্ক্রিয়া এবং রৈখিক উপস্থিতি:''' যদি প্রত্যেকটি বৈশিষ্ট্য পৃথকভাবে ফলাফলের উপর প্রভাব বিস্তার করে, তবে লিনিয়ার রিগ্রেশন, লজিস্টিক রিগ্রেশন, সাপোর্ট ভেক্টর মেশিন এর মত অ্যালগরিদম গুলো ভালো ফলাফল দেয়। যদি বৈশিষ্ট্য গুলোর মধ্যে জটিল মিথস্ক্রিয়া বিদ্যমান থাকে তবে সিদ্ধান্ত বৃক্ষ এবং কৃত্রিম নিউরাল নেটওয়ার্ক ভালো কাজ করে, কারণ তারা এসব মিথস্ক্রিয়ার জন্য বিশেষভাবে ডিজাইনকৃত। এক্ষেত্রে লৈখিক পদ্ধতিও ব্যবহার করা যেতে পারে, তবে একজন ইঞ্জিনিয়ার অবশ্যই সেটা উল্লেখ করে দিতে হবে কখন মিথস্ক্রিয়া কাজ করবে। নতুন কোন প্রয়োগ বিবেচনার সময় একজন ইঞ্জিনিয়ার বিভিন্ন প্রশিক্ষণ অ্যালগরিদম হাতে কলমে তুলনা করবেন এবং পরীক্ষা করে দেখবেন কোনটি সবচেয়ে ভালো কাজ করে। (see cross validation). প্রশিক্ষণ অ্যালগোরিদমের পারফরম্যান্স যাচাই অনেক সময় সাপেক্ষ ব্যাপার হতে পারে। সীমাবদ্ধ উপাত্তের ক্ষেত্রে যাচাইকরণের বদলে আরো প্রশিক্ষণ উপাত্ত এবং তথ্যমূলক বৈশিষ্ট্য সঞ্চয়কে প্রাধান্য দিতে হবে। অধিক ব্যবহৃত প্রশিক্ষণ অ্যালগরিদমগুল হল: *সাপোর্ট ভেক্টর মেশিন *linear regression *logistic regression *naive Bayes *linear discriminant analysis *decision trees *k-nearest neighbor algorithm *কৃত্রিম নিউরাল নেটওয়ার্ক (Multilayer perceptron) *Similarity learning == কিভাবে সুপারভাইজ লার্নিং কাজ করে == একটি প্রশিক্ষণ উপাত্তের সেট দেয়া আছে যার গঠন যেন -তম উপাত্তের বৈশিষ্ট্য ভেক্টর এবং এর নির্দেশক (অর্থাৎ, শ্রেণী) একটি প্রশিক্ষণ অ্যালগরিদম এমন একটি ফাংশন খুঁজবে, যেখানে হল '''গ্রহণ ক্ষেত্র''' (Input Space) এবং হল ''''ফলাফল ক্ষেত্র''' (Output Space)। ফাংশনটিকে বলা হয় ''অনুমান ক্ষেত্র'' ('''Hypothesis space''') নামক সম্ভাব্য সকল ফাংশনের ক্ষেত্র এর একটি উপাদান। কে মাঝেমাঝে আকারে প্রকাশ করা হয় যেখানে সর্বোচ্চ মান দেয়া সমূহ কে সংজ্ঞায়িত করে। ধরি, হল সকল স্কোরিং ফাংশনের ক্ষেত্র। যদিও এবং ফাংশনের যেকোনো ক্ষেত্র হতে পারে, অনেক প্রশিক্ষণ অ্যালগরিদম এমনভাবে সম্ভাব্য মডেল তৈরি করে যেন শর্তাধীন সম্ভাবনা মডেল অথবা সংযুক্ত সম্ভাবনা মডেল গ্রহণ করে। অথবা নির্বাচন করার দুটি মৌলিক পদ্ধতি রয়েছে প্রযুক্ত ঝুঁকি হ্রাসকরণ এবং গাঠনিক ঝুঁকি হ্রাসকরণ. প্রযুক্ত ঝুঁকি হ্রাস করণ এমন ফাংশন খুঁজে, যা প্রশিক্ষণ উপাত্তের সঙ্গে সর্বোত্তমভাবে মানানসই হয়। গাঠনিক ঝুঁকি হ্রাসকরণ ধ্রুবক-ভেদাঙ্ক সমন্বয় নিয়ন্ত্রণ করে। উভয় ক্ষেত্রে ধরা হয় যে, উপাত্ত সমূহ স্বাধীন এবং সমবিভাজিত আকারে বিস্তৃত। কিভাবে একটি ফাংশন প্রশিক্ষণ উপাত্ত সমূহের সঙ্গে মানানসই হয়, তা পরিমাপ করার জন্য একটি ঋণ ফাংশন ('''Loss function''') সংজ্ঞায়িত করা হয়। প্রশিক্ষণ উপাত্তের জন্য এর বিচ্যুতি ফাংশনের '''ঝুঁকি''' এর প্রত্যাশিত বিচ্যুতি হিসেবে সংজ্ঞায়িত করা হয়। প্রশিক্ষণ উপাত্ত হতে হিসাব করা হয়: ===প্রযুক্ত ঝুঁকি হ্রাসকরণ === প্রযুক্ত ঝুঁকি হ্রাসকরণে প্রশিক্ষণ অ্যালগরিদমটি এমন একটি ফাংশন খুঁজে যা কে ন্যূনতম করে। এভাবে সুপারভাইজ প্রশিক্ষণ অ্যালগরিদম কে অনুকূল করে এমন ফাংশন দ্বারা খুব সহজেই গঠন করা যায়। যখন একটি শর্তাধীন সম্ভাব্য বিভাজন এবং ঋণ ফাংশনটি ঋণাত্মক লগারিদম: তখন প্রযুক্ত ঝুঁকি হ্রাসকরন সর্বাধিক সম্ভাব্য অনুমানের ('''Maximum likelihood estimation''') এর মতো হয়। যখন প্রশিক্ষণ সেটটি যথেষ্ট বড় নয় কিংবা একাধিক উপযুক্ত ফাংশন অন্তর্ভুক্ত থাকে তখন প্রযুক্ত ঝুঁকি হ্রাসকরণ উচ্চ ভেদাঙ্ক এবং নিম্ন ধ্রুবকের দিকে গমন করে। প্রশিক্ষণ অ্যালগরিদমটি যথাযথ সাধারণীকরণ ব্যতিরেকেই প্রশিক্ষণ উপাত্তগুলো মুখস্ত করতে শুরু করে। একে বলা হয় অতিমান্যতা (overfitting)। === গাঠনিক ঝুঁকি হ্রাসকরণ === গাঠনিক ঝুঁকি হ্রাসকরণ অতিমান্যতা রোধ করতে আনুকূল্যকরণে নিয়মিতকরণ ঋণ যুক্ত করে। নিয়মিতকরণের ঋণকে অকামের রেজার এর প্রয়োগ হিসেবে দেখা যেতে পারে, যা অনেক জটিল ফাংশন থেকে সরলতর ফাংশন কে বেশি প্রাধান্য দেয়। বিভিন্ন জটিলতার বিভিন্ন ঋণ ব্যবহার করা হয়। উদাহরণস্বরূপ, একটি ক্ষেত্রে ফাংশনটি: গঠনের একটি রৈখিক ফাংশন। একটি জনপ্রিয় নিয়মিতকরণ ঋণ হল যা সহগসমূহের ইউক্লিডীয় নিয়মিতকরণ এর বর্গ যা নিয়মিতকরণ নামে পরিচিত। অন্যান্য নিয়মিতকরণ গুলোর মধ্যে রয়েছে নিয়মিতকরন নিয়মিতকরণ যা অশূন্য সমূহের সংখ্যা। ঋণকে দ্বারা প্রকাশ করা হয়। == গঠনমূলক প্রশিক্ষণ == উপরোক্ত প্রশিক্ষণ পদ্ধতি গুলো পার্থক্যসূচক প্রশিক্ষণ পদ্ধতি, কেননা তারা এমন একটি ফাংশন খুঁজে, যা বিভিন্ন ফলাফল এর মান কে পার্থক্য করে।(দেখুন discriminative model)। বিশেষ ক্ষেত্রে, যখন একটি সংযুক্ত সম্ভাবনা বিভাজন এবং ঋণ ফাংশনটি ঋণাত্মক লগারিদম তখন ঝুঁকি হ্রাসকরণ অ্যালগরিদম গঠনগত প্রশিক্ষণ শুরু করে। কারণ কে গঠনগত মডেল হিসেবে ধরা যেতে পারে, যা ব্যাখ্যা করে কিভাবে উপাত্তগুলোর উৎপত্তি হয়েছিল। গঠনমূলক প্রশিক্ষণ অ্যালগরিদমগুলো প্রায়ই পার্থক্যসূচক অ্যালগরিদমগুলোর চেয়ে সরল এবং সহজে হিসাবযোগ্য। == সাধারণীকরণ == আদর্শ সুপারভাইজ লার্নিং সমস্যা বিভিন্ন পদ্ধতিতে সাধারণীকৃত হতে পারে: শিক্ষণ: শুধুমাত্র প্রশিক্ষণ উপাত্তের একটি উপসেটের জন্য ফলাফলগুলো দেওয়া থাকে এবং অন্য গুলো অবিন্যস্ত থাকে। সক্রিয় শিক্ষণ: সবগুলো প্রশিক্ষণ উপাত্ত প্রথমে আছে ধরে নেওয়ার বদলে সক্রিয় শিক্ষণ অ্যালগরিদম একজন ব্যবহারকারীর কাছে প্রশ্নের মাধ্যমে উপাত্ত গ্রহণ করে। গাঠনিক অনুমান: যখন প্রত্যাশিত ফলাফল মান কোন জটিল অবজেক্ট যেমন পার্স ট্রি অথবা চিহ্নিত গ্রাফ, তখন আদর্শ পদ্ধতি গুলো বর্ধিতকরণ করতে হয়। বিন্যস্তকরণ শিখন: যখন কিছু অবজেক্ট এর সেট ইনপুট এবং তাদের ক্রম ফলাফল হিসেবে থাকে, তখন আবার আদর্শ পদ্ধতিগুলো বর্ধিতকরণ আবশ্যক। == পদ্ধতি এবং অ্যালগরিদমসমূহ == বিশ্লেষণী শিক্ষণ কৃত্রিম নিউরাল নেটওয়ার্ক পশ্চাদপ্রসারণ সম্মুখায়ন (অ্যালগরিদম) বায়েসীয় পরিসংখ্যান ক্ষেত্রভিত্তিক কার্যকারণ সিদ্ধান্তবৃক্ষ শিক্ষণ আরোহী যুক্তিভিত্তিক শিক্ষণ গাউসীয় প্রত্তাবৃত্তি জেনেটিক প্রোগ্রামিং উপাত্ত ব্যবস্থাপনার গুচ্ছ পদ্ধতি কার্নেল প্রাক্কলন স্বয়ংশিক্ষণ শ্রেণীকারক শিক্ষণ পদ্ধতি সর্বনিম্ন ম্যাসাজ পদ্ধতি (সিদ্ধান্তবৃক্ষ শিক্ষণ, সিদ্ধান্ত লেখ, ইত্যাদি) বহুরৈখিক উপক্ষেত্র শিক্ষণ নাইভ বায়েস শ্রেণীকরণ সর্বোচ্চ এনট্রপি শ্রেণীকারক শর্তভিত্তিক দৈবক্ষেত্র নিকটবর্তী প্রতিবেশী অ্যালগরিদম সম্ভাব্য নিকটবর্তী শিক্ষন (PAC) পদ্ধতি নিম্ন তারঙ্গিক বিধি, জ্ঞানান্বেষণ পদ্ধতি প্রতিকী যান্ত্রিক জ্ঞানার্জন প্রক্রিয়া উপপ্রতিকী যান্ত্রিক জ্ঞানার্জন প্রক্রিয়া সাপোর্ট ভেক্টর মেশিন সর্বনিম্ন জটিল যন্ত্র (MCM) দৈব অরণ্য শ্রেণীকরণের সামগ্রীকীকরণ ক্রমিক শ্রেণীকরণ উপাত্ত ভারসাম্যহীন উপাত্ত ব্যবস্থাপনা পারিসাংখ্যিক সম্পর্ক শিক্ষণ প্রোয়াফটন, একাধিক শর্তাধীন অ্যালগরিদম == প্রয়োগ == জৈব তথ্যবিজ্ঞান রাসায়নিক তথ্যবিজ্ঞান **Quantitative relationship ডেটাবেজ ব্যবসা হস্তলিপি শনাক্তকরণ তথ্য পুনরুদ্ধার ** Learning to rank তথ্য ছাঁকনী কম্পিউটার দর্শন বস্তু শনাক্তকরণ অপটিক্যাল ক্যারেক্টার রিকগনিশন স্প্যাম শনাক্তকরণ বিন্যাস সনাক্তকরণ কন্ঠ সনাক্তকরণ জীববিজ্ঞানের Downward causation এর বিশেষ রূপ হল Supervised Learning == সাধারণ বিষয় == নির্ণায়িক শিক্ষণ পদ্ধতি আরোহী বিধি অতিমান্যতা (যান্ত্রিক জ্ঞানার্জন) (অক্রমাঙ্কিত) শ্রেণী সদস্য সম্ভাবনা অদৃষ্ট শিক্ষণ সংস্করণ ক্ষেত্র ==তথ্যসূত্র== == আরো দেখুন == যান্ত্রিক জ্ঞানার্জনের জন্য গবেষণাসমূহ মেশিন লার্নিং ==বহিঃসংযোগ== Machine Learning Open Source Software (MLOSS) learning মাইনিং