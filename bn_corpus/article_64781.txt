মেশিন লার্নিং এর ক্ষেত্রে '''ফিচার লার্নিং''' বা রিপ্রেজেন্টেশন লার্নিং এমন একটি সেট যা একটি সিস্টেমকে তথ্য থেকে বৈশিষ্ট্য সনাক্তকরণ বা শ্রেণীবিভাগের জন্য প্রয়োজনীয় উপস্থাপনাগুলি প্রকাশ করতে দেয়। এটি ম্যানুয়াল ফিচার ইঞ্জিনিয়ারিংকে প্রতিস্থাপন করে এবং একটি মেশিনকে ফিচার লার্নিং এর একটি নির্দিষ্ট টাস্ক সম্পাদন ব্যবহার করার অনুমতি দেয়। ফিচার লার্নিং আসলে মেশিন লার্নিং এর দ্বারা অনুপ্রাণিত। এর কাজগুলো করার ক্ষেত্রে প্রায়ই গণিত এবং গাণিতিক হিসাব প্রক্রিয়াকরণ করার জন্য উপযুক্ত ইনপুট প্রয়োজন। যাইহোক,এটি চিত্র, ভিডিও এবং সেন্সর ডেটা যেমন ডেটা আলগোরিদমিক নির্দিষ্ট বৈশিষ্ট্যগুলি সংজ্ঞায়িত করার জন্য উৎপন্ন হয় নি। এটি একটি বিকল্প স্পষ্ট আলগোরিদম পরীক্ষার মাধ্যমে যার দ্বারা বৈশিষ্ট্য বা উপস্থাপনা আবিষ্কার করা হয় তেমন বিষয়গুলোর উপর নির্ভর করে। ফিচার লার্নিং হতে পারে সুপারভাইজড কিংবা আনসুপারভাইজড। *সুপারভাইজড লার্নিং এর ক্ষেত্রে বৈশিষ্ট্যগুলো হয় লেবেলযুক্ত ইনপুট ডেটা। উদাহরণ হিসেবে বলা যায়, সুপারভাইজড স্নায়ু নেটওয়ার্ক, মাল্টিলেয়ার পারসেপট্রন এবং ডিকশনারি লার্নিং হল এর অন্তর্ভুক্ত। *আনসুপারভাইজড লার্নিং এর ক্ষেত্রে, বৈশিষ্ট্যগুলি হয় আনলেবেলড ইনপুট ডেটা। উদাহরণ হিসেবে বলা যায়, ডিকশনারি লার্নিং, স্বাধীন উপাদান বিশ্লেষণ, অটো এনকোডার, ম্যাট্রিক্স ফ্যাক্টরাইজেশন এবং ক্লাস্টারিংয়ের বিভিন্ন রূপ এর অন্তর্ভুক্ত। == সুপারভাইজড == সুপারভাইজড ফিচার লার্নিং এর ক্ষেত্রে লেবেলযুক্ত তথ্য থেকে বৈশিষ্ট্য শিখে নেওয়া যায়। ডেটা লেবেল সিস্টেমকে একটি ত্রুটি শব্দ বা কোন ডিগ্রী গণনা করতে দেয় যার ফলে সিস্টেমটি লেবেল উৎপাদন করতে ব্যর্থ হয়, যা তখন শেখার প্রক্রিয়াটি সংশোধন করতে (প্রতিক্রিয়াটি হ্রাস কমিয়ে আনতে) ব্যবহার হয়। প্রক্রিয়াগুলোর অন্তর্ভুক্ত হচ্ছেঃ === সুপারভাইজড ডিকশনারি লার্নিং === ডিকশনারি লার্নিং ইনপুট ডেটা থেকে উপাদানগুলির একটি সেট (অভিধান) প্রকাশ করে, যেমন প্রতিটি তথ্য বিন্দু প্রতিনিধি উপাদানের ওজনযুক্ত সমষ্টি হিসাবে প্রকাশ করা যেতে পারে। ডিকশনারি উপাদানগুলি এবং ওজনগুলি সাধারণ্ত ত্রুটি (ইনপুট ডেটাতে) কমিয়ে আনতে পারে, এবং একইসাথে স্পষ্টতা এনাবল (সক্ষম) করার জন্য ওজনে L1 নিয়মিতকরণ করে থাকে। সুপারভাইজড ডিকশনারি লার্নিং উপাদানের অপ্টিমাইজেশনের জন্য ইনপুট ডেটা এবং লেবেলগুলির অন্তর্গত গঠন উভয়ই শোষণ করে। উদাহরণস্বরূপ, একটি সুপারভাইজড ডিকশনারি লার্নিং ডিকশনারির উপাদান যৌথভাবে অপ্টিমাইজ করে এবং ইনপুট ডেটার উপর ভিত্তি করে পরামিতি দ্বারা শ্রেণিকরণ করার পর সমস্যাগুলিতে ডিকশনারি লার্নিং প্রয়োগ করে। বিশেষত, একটি ক্ষুদ্রীকরণ সমস্যা প্রণয়ন করা হয় যেখানে উদ্দেশ্য ফাংশন শ্রেণীবিভাগ ত্রুটি, প্রতিনিধিত্ব ত্রুটি, প্রতিটি ডাটা পয়েন্টের জন্য ডেটা স্পার উপস্থাপনা সক্ষম করতে এবং পরামিতিক ক্লাসিফায়ারে মাধ্যমে L2 নিয়মিতকরণ করে থাকে। === নিউরাল নেটওয়ার্ক === নিউরাল নেটওয়ার্কগুলি হল আলগোরিদম শেখার জন্য একটি পরিবার যা একটি "নেটওয়ার্ক" ব্যবহার করে আন্তঃ-সংযুক্ত নোডগুলির একাধিক স্তরের সাথে অন্তর্ভুক্ত। এটি পশু স্নায়ুতন্ত্রের দ্বারা অনুপ্রাণিত, যেখানে নোডগুলিকে নিউরন হিসাবে দেখা হয় এবং প্রান্তগুলিকে সিন্যাপসিস হিসাবে দেখা হয়। নেটওয়ার্কটির ইনপুট লেয়ার থেকে ইনপুট ডেটা পাস করার জন্য নেটওয়ার্ক কম্পিউটেশনাল নিয়মগুলি অনুসরণ করে। একটি স্নায়ুতন্ত্রের সাথে যুক্ত নেটওয়ার্ক ফাংশনের ইনপুট এবং আউটপুট স্তরের মধ্যে সম্পর্ককে চিহ্নিত করে, যা ওজন নামক পরামিতি দ্বারা সঙ্গায়িত। ফিচার লার্নিং এর জন্য মাল্টিলেয়ার স্নায়ু নেটওয়ার্ক ব্যবহার করা যেতে পারে।এই ধরনের নেটওয়ার্কগুলোর মধ্যে সবচেয়ে জনপ্রিয় নেটওয়ার্ক আর্কিটেকচার হল সিয়ামিজ নেটওয়ার্ক। == আনসুপারভাইজড == আনসুপারভাইজড ফিচার লার্নিং হল আনলেভেলড তথ্য থেকে বৈশিষ্ট্য শেখা। আনসুপারভাইজড ফিচার লার্নিং এর লক্ষ্য হল উচ্চ মাত্রিক ইনপুট ডেটা ক্যাপচার করে নিম্ন-মাত্রিক বৈশিষ্ট্য আবিষ্কার করা। যখন ফিচার লার্নিং একটি অপ্রচলিত উপায়ে সঞ্চালিত হয়, তখন এটি অর্ধপ্রচলিত শিক্ষার একটি ফর্ম তৈরি করে যেখানে একটি আনলেবেড ডেটা সেট থেকে বৈশিষ্ট্যগুলি শিখে লেবেলযুক্ত ডেটা উন্নত করতে কাজ করে। এজন্য আরো বিভিন্ন ধরনের পদ্ধতি অনুসরণ করা হয়। === K- মিনস ক্লাস্টারিং === K-মিনস ক্লাস্টারিং ভেক্টর একটি পদ্ধতি। বিশেষ করে, ভেক্টরগুলির একটি সেট দেওয়া হয়, কে-মিনস ক্লাস্টারিং সেগুলোকে ক্লাস্টার (যেমন, উপসেট) গ্রুপ করে যাতে প্রতিটি ভেক্টর ক্লাস্টারের কাছাকাছি অর্থ বহন করে। K-means ক্লাস্টারিং ক্লাস্টারগুলিতে ইনপুটগুলির একটি আনলবেড সেট গ্রুপিং করার জন্য ব্যবহার করা যেতে পারে এবং তারপরে বৈশিষ্ট্যগুলি তৈরি করতে এই ক্লাস্টারগুলির সেন্ট্রোডগুলি ব্যবহার করা হয়। এই বৈশিষ্ট্য বিভিন্ন উপায়ে উৎপাদিত হতে পারে। সবচেয়ে সহজ হল প্রতিটি নমুনাতে বাইনারি বৈশিষ্ট্যগুলি যোগ করা, যেখানে প্রতিটি বৈশিষ্ট্য তে একটি আইএফএফ (IFF) মান থাকে। এটাও সম্ভব যে রেডিয়াল বেস ফাংশন (RBF নেটওয়ার্কগুলি প্রশিক্ষণের জন্য ব্যবহৃত একটি কৌশল) দ্বারা রূপান্তরিত হওয়ার পরে, ক্লাস্টারগুলির বৈশিষ্ট্য হিসাবে দূরত্বগুলিও ব্যবহার করা যেতে পারে। === প্রধান উপাদান বিশ্লেষণ === প্রিন্সিপাল কম্পোনেন্ট বিশ্লেষণ (পিসিএ) প্রায়শই মাত্রা কমানোর জন্য ব্যবহৃত হয়। প্রদত্ত ইনপুট ডেটা ভেক্টরগুলির একটি আনলেভেলড সেট। এই একক ভেক্টরগুলি আইগেন ভেক্টর ইনপুট ভেক্টরের নমুনা কোভেরিয়েন্স ম্যাট্রিক্সের বৃহত্তম আইগেনভ্যালুর অনুরূপ। ইনপুট তথ্য থেকে শেখা বৈশিষ্ট্য ভেক্টর হল একক ভেক্টর এবং তারা এমন দিক নির্দেশ করে যেখানে বৃহৎ তথ্য বৈচিত্র আছে। PCA একটি লিনিয়ার ফিচার লার্নিং পদ্ধতি যেখানে একক ভেক্টরটি ডাটা ম্যাট্রিক্সের লিনিয়ার ফাংশন। এই একক ভেক্টর পুনরাবৃত্তি একটি সহজ অ্যালগরিদম এর মাধ্যমে উৎপন্ন হয়ে থাকে। i-th পুনরাবৃত্তিতে, (i-1) তম আইগেন ভেক্টরের ডেটা ম্যাট্রিক্সের অভিক্ষেপ হ্রাস করা হয় এবং i-th একক ভেক্টরটি অবশিষ্ট ডেটা ম্যাট্রিক্সের একাধিক একক ভেক্টর হিসাবে পাওয়া যায়। PCA এর বিভিন্ন সীমাবদ্ধতা আছে। প্রথমত, সর্বাধিক আগ্রহের বৃহৎ দিকগুলি অনেক ক্ষেত্রে নাও মিলতে পারে। PCA শুধুমাত্র মূল ডেটার অর্থোগনাল রূপান্তরের উপর নির্ভর করে এবং এটি কেবলমাত্র প্রথম এবং ডেটা শোষণ করে যা ডেটা বণ্টনকে ভালভাবে চিহ্নিত করতে পারে না। অধিকন্তু, ইনপুট ডেটা ভ্যাক্টরগুলি যখন সম্পর্কযুক্ত হয় তখন PCA কার্যকরভাবে মাত্রা হ্রাস করতে পারে (যা কিছু কিছু ক্ষেত্রে আইগেনভ্যালুতে প্রভাব ফেলে)। === লোকাল লিনিয়ার এম্বেডিং === লোকাল লিনিয়ার এম্বেডিং (এল এল ই) উচ্চ-মাত্রিক ইনপুট থেকে নিম্ন-মাত্রিক উপস্থাপনাগুলি তৈরির জন্য একটি অনন্য লার্নিং পদ্ধতি। এলএলই এর সাধারণ ধারণা হল মূল তথ্য সেটের আশেপাশের কিছু জ্যামিতিক বৈশিষ্ট্য বজায় রাখার সময় নিম্ন-মাত্রিক পয়েন্টগুলি ব্যবহার করে মূল উচ্চ-মাত্রিক ডেটা পুনঃনির্মাণ করা। এলএলই (LLE) এর দুটি প্রধান ধাপ রয়েছে। প্রথম পদক্ষেপটি হল জন্য, যেখানে প্রতিটি ইনপুট ডেটা পয়েন্ট Xi কে নিকটতম ডেটা পয়েন্টের ওজনযুক্ত সমষ্টি হিসাবে পুনঃনির্মিত করা হয় এবং সর্বোত্তম ওজনের গড় বর্গ পুনর্নির্মাণের ত্রুটির প্রতিটি বিন্দুর সঙ্গে যুক্ত ওজন সংহত থাকে। দ্বিতীয় ধাপটি হল "মাত্রা হ্রাসকরণ" এর জন্য নিম্ন-মাত্রিক স্থানটিতে ভেক্টরগুলি সন্ধান করে যা প্রথম ধাপে অপ্টিমাইজেশন করা ওজনগুলি ব্যবহার করে প্রতিনিধিত্ব ত্রুটি কমিয়ে দিতে পারে। উল্লেখ্য যে প্রথম ধাপে, ওজন স্থির ডেটা দ্বারা অপ্টিমাইজ করা হয়, যা অন্তত স্কয়ার সমস্যা হিসাবে সমাধান করা যেতে পারে। দ্বিতীয় ধাপে, নিম্ন-মাত্রিক বিন্দু স্থির ওজনের সাথে অপ্টিমাইজ করা হয়, যা স্পারসে আইগেন ভ্যালু বিচ্ছিন্নকরণের মাধ্যমে সমাধান করা যেতে পারে। প্রথম ধাপে প্রাপ্ত পুনর্গঠিত ওজনগুলি ইনপুট ডেটাতে একটি "অন্তর্নিহিত জ্যামিতিক বৈশিষ্ট্য" ক্যাপচার করে। এটি ধরে নেওয়া হয় যে আসল তথ্য একটি মসৃণ নিম্ন-মাত্রিক অবস্থানে থাকে এবং মূল তথ্যের ওজন দ্বারা গৃহীত "অভ্যন্তরীণ জ্যামিতিক বৈশিষ্ট্য" বিবিধও হতে পারে। কারণেই এলইএ্রলই এর দ্বিতীয় ধাপে একই ওজন ব্যবহার করা হয়। === স্বাধীন উপাদান বিশ্লেষণ === স্বাধীন উপাদান বিশ্লেষণ (ICA) ডেটা উপস্থাপনার একটি কৌশল যা একটি স্বাধীন অ-গাউসিয়ান উপাদানগুলিকে ওজন যুক্ত করে অ-গাউসিয়ান অনুমেয় আরোপ করা যায় না এমন সমস্ত উপাদান গাউসিয়ান বিতরণকে অনুসরণ করে। === আনসুপারভাইজড ডিকশনারি লার্নিং === আনসুপারভাইজড ডিকশনারি লার্নিং ডেটা লেবেলগুলি ব্যবহার করে না এবং ডিকশনারি উপাদানের অপ্টিমাইজেশনের জন্য ডেটা অন্তর্নিহিত কাঠামোতে শোষণ করে না। আনসুপারভাইজড ডিকশনারি লার্নিং এর একটি উদাহরণ স্পারস কোডিং যা্র লক্ষ্য হচ্ছে ডেটা উপস্থাপনার জন্য বেসিক ফাংশন (ডিকশনারি উপাদানের মত) শিখা। অসম্পূর্ণ অভিধানগুলি শিখতে স্পার্স কোডিং প্রয়োগ করা যেতে পারে, যেখানে অভিধান উপাদানগুলির সংখ্যা ইনপুট ডেটার মাত্রার চেয়ে বড়। == আর্কিটেকচার == জৈবিক স্নায়ুতন্ত্রের অনুক্রমিক স্থাপত্যটি শেখার জন্য ফিচার লার্নিং নোডের একাধিক স্তরের স্ট্যাকিংয়ের মাধ্যমে এর জন্য ডিপ লার্নিং স্থাপত্যকে অনুপ্রাণিত করে। এই আর্কিটেকচারগুলি প্রায়শই ডিস্ট্রিবিউটেড উপস্থাপনার ধারণার উপর ভিত্তি করে ডিজাইন করা হয়। প্রতিটি স্তরে ইনপুট হিসাবে পূর্ববর্তী স্তর দ্বারা উৎপাদিত উপস্থাপনা ব্যবহার করা হয়ে থাকে এবং আউটপুট হিসাবে নতুন উপস্থাপনা তৈরি করে, যা পরে উচ্চ স্তরে পাঠানো হয়। নিচের স্তরে ইনপুট হচ্ছে রো ডেটা এবং চূড়ান্ত স্তরটির আউটপুট হচ্ছে চূড়ান্ত নিম্ন-মাত্রিক ডেটা। === সীমাবদ্ধ বোল্টসম্যান মেশিন === সীমাবদ্ধ বোল্টজমান মেশিন (আরবিএম) প্রায়শই মাল্টিলেয়ার লার্নিং আর্কিটেকচারের জন্য একটি বিল্ডিং ব্লক হিসাবে ব্যবহার করা হয়। একটি RBM এর একটি অনির্দেশিত বাইপার্টাইট গ্রাফ দ্বারা নিয়ন্ত্রণ করা হয়ে থাকে যা বাইনারিতে লুকানো ভেরিয়েবলগুলির একটি গ্রুপ যা দৃশ্যমান ভেরিয়েবলের একটি গোষ্ঠী আর লুকানো এবং দৃশ্যমান নোডগুলিকে সংযুক্ত করে। এটি আন্তঃ-নোড সংযোগগুলির সংকোচনের সাথে আরও সাধারণ বোল্টজমান মেশিনগুলির একটি বিশেষ ক্ষেত্র। একটি আরবিএম এর প্রতিটি প্রান্ত একটি ওজন এর সঙ্গে যুক্ত করা হয়। একটি RBM অসমর্থিত ফিচার লার্নিং এর জন্য একটি একক স্তর আর্কিটেকচার ব্যবহার করা যেতে পারে। বিশেষত, দৃশ্যমান ভেরিয়েবল ইনপুট ডেটার সাথে এবং লুকানো ভেরিয়েবলগুলি বৈশিষ্ট্য ডিটেক্টরের সাথে সম্পর্কিত। হিন্টন এর বৈষম্যমূলক বিভাজন (সিডি) অ্যালগরিদম ব্যবহার করে দৃশ্যমান ভেরিয়েবলগুলির সম্ভাব্যতা সর্বাধিক ওজনসমূহ দ্বারা প্রশিক্ষিত করা সম্ভব। সাধারণত RBM প্রশিক্ষিত হয় মেক্সিমাইজেশন সমস্যা সমাধানের দ্বারা এবং উপস্থাপনা ফলাফল অ-স্পারস প্রদর্শিত হয় স্পারস আরবিএম কে স্পারস উপস্থাপনা এনাবল করার প্রস্তাব করা হয়েছিল। ধারণাটি হচ্ছে ডাটা সম্ভাব্যতার সম্ভাব্য ফাংশনে একটি নিয়মিতকরণ শব্দ যোগ করা, যা একটি ছোট ধ্রুবক প্রত্যাশিত লুকানো ভেরিয়েবলগুলির বিচ্যুতিকে আটকে দেয়। === অটোএনকোডার === একটি এনকোডার এবং একটি ডিকোডার ধারণকারী একটি অটোএনকোডার ডিপ লার্নিং আর্কিটেকচারের একটি আদর্শ। যেমন, এনকোডার ইনপুট হিসাবে রো (Raw) তথ্য (যেমন, চিত্র) ব্যবহার করে এবং আউটপুট হিসাবে বৈশিষ্ট্য বা উপস্থাপনা তৈরি করে এবং ডিকোডার এনকোডার থেকে প্রাপ্ত এক্সট্রাক্ট বৈশিষ্ট্যটি ব্যবহার করে এবং মূল ইনপুট রো ডেটা আউটপুট হিসাবে পুনর্নির্মাণ করে। এনকোডার এবং ডিকোডারটি আরবিএম (RBM)গুলি একাধিক স্তরে স্ট্যাক করে তৈরি করে। আর্কিটেকচারের সাথে জড়িত পরামিতিগুলি মূলত পদ্ধতিতে প্রশিক্ষিত হয়ে থাকে। বর্তমান পদ্ধতিগুলি সাধারণত স্টোকাস্টিক গ্রেডিয়েন্ট পদ্ধতিগুলির সাথে শেষ থেকে শেষ (end-to-end) প্রশিক্ষণ প্রয়োগ করে। মানদণ্ড পূর্ণ না হওয়া পর্যন্ত প্রশিক্ষণ পুনরাবৃত্তি করা যায়। ==আরো দেখুন== *স্বয়ংক্রিয় মেশিন লার্নিং (AutoML) বেসিস ফাংশন ডিপ লার্নিং ফিচার vision) ফিচার এক্সট্রাকশন কার্নাল ট্রিক ভেক্টর কোয়ান্টাইজেশন ==References==