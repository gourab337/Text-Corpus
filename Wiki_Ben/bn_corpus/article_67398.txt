পুনরাবৃত্ত স্নায়ু বা নিউরাল নেটওয়ার্ক (আরএনএন) হচ্ছে কৃত্রিম বুদ্ধিমত্তা নেটওয়ার্কের একটি শ্রেণী যেখানে নোডগুলোর মধ্যকার সংযোগগুলো গঠন করে অস্থায়ী ধারা বরাবর একটি নির্দেশিত গ্রাফ এটা ইহাকে অস্থায়ী গতিশীল আচরণ প্রদর্শন করতে অনুমতি দেয় ফিডফোরওয়ার্ড নিউরাল নেটওয়ার্কগুলির বিপরীতে, আরএনএনগুলি ইনপুটগুলির ক্রমগুলি প্রক্রিয়া করতে তাদের অভ্যন্তরীণ অবস্থা (মেমরি) ব্যবহার করতে পারে। এটি অখণ্ডিত, সংযুক্ত হাতের লেখা শনাক্তকরণ বা বক্তৃতা শনাক্তকরণ ইত্যাদির মতো কাজের ক্ষেত্রে এগুলিকে প্রযোজ্য করে তোলে "পুনরাবৃত্ত নিউরাল নেটওয়ার্ক" শব্দটি একই রকমের সাধারণ কাঠামোর সাথে দুটি বিস্তৃত শ্রেণীর নেটওয়ার্ককে বোঝাতে নির্বিচারে ব্যবহৃত হয়, যেখানে একটি সসীম ইমপালস এবং অন্যটি অসীম ইমপালস উভয় শ্রেণীর নেটওয়ার্ক অস্থায়ী গতিশীল আচরণ প্রদর্শন করে একটি সসীম ইমপালস পুনরাবৃত্তি নেটওয়ার্ক একটি নির্দেশিত অচক্রাকার গ্রাফ যা অনিয়ন্ত্রিত এবং কঠোরভাবে ফিডফোরওয়ার্ড নিউরাল নেটওয়ার্কের সাথে প্রতিস্থাপন করা যেতে পারে, অন্যদিকে অসীম ইমপালস পুনরাবৃত্তি নেটওয়ার্ক একটি নির্দেশিত চক্রাকার গ্রাফ যা অনিয়ন্ত্রিত হতে পারে না। উভয় সসীম ইমপালস এবং অসীম ইমপালস পুনরাবৃত্ত নেটওয়ার্কগুলির অতিরিক্ত সঞ্চিত মেমরি থাকতে পারে এবং স্টোরেজটি নিউরাল নেটওয়ার্কের মাধ্যমে সরাসরি নিয়ন্ত্রণে থাকতে পারে। স্টোরেজটি অন্য নেটওয়ার্ক বা গ্রাফ দ্বারা প্রতিস্থাপন করা যেতে পারে, যদি এতে সময় বিলম্ব অন্তর্ভুক্ত হয় বা প্রতিক্রিয়া লুপ থাকে। এই জাতীয় নিয়ন্ত্রিত মেমরিগুলিকে গেটেড স্টেট বা গেটেড মেমরি হিসাবে উল্লেখ করা হয় এবং এটি দীর্ঘ স্বল্প-মেয়াদী মেমরি নেটওয়ার্ক (এলএসটিএম) এবং গেটেড পুনরাবৃত্ত ইউনিটগুলির অংশ == ইতিহাস == ১৯৮৬ সালে ডেভিড রুমেলহার্টের কাজের ভিত্তিতে পুনরাবৃত্ত নিউরাল নেটওয়ার্কগুলি ছিল হপফিল্ড নেটওয়ার্কগুলির একটি বিশেষ ধরনের আরএনএন, ১৯৮২ সালে জন হপফিল্ড আবিষ্কার করেছিলেন। ১৯৯৩ সালে একটি নিউরাল হিস্ট্রি সংক্ষিপ্ত সিস্টেম একটি "খুব গভীর শিখুন" কাজটি সমাধান করেছিল যার জন্য আরএনএন-এর পরবর্তী সময়ে ১০০০ টিরও বেশি স্তর সময়মতো প্রকাশিত হয়েছিল। === এলএসটিএম === দীর্ঘ স্বল্পমেয়াদী মেমরি (এলএসটিএম) নেটওয়ার্কগুলি 1997 সালে হোচ্রেইটার এবং শ্মিধুবার আবিষ্কার করেছিলেন এবং একাধিক অ্যাপ্লিকেশন ডোমেনে নির্ভুলতার রেকর্ড স্থাপন করেছিল ২০০৭ সালের দিকে, এলএসটিএম নির্দিষ্ট বক্তৃতার ঐতিহ্যবাহী মডেলকে ছাপিয়ে বক্তৃতা স্বীকৃতিতে বৈপ্লবিক পরিবর্তন শুরু করে ২০০৯-এ, সংযুক্ত হাতের লেখার স্বীকৃতিতে বেশ কয়েকটি প্রতিযোগিতা জিতেছে তখন একটি সংযোগবাদী টেম্পোরাল শ্রেণিবিন্যাস (সিটিসি) প্রশিক্ষিত এলএসটিএম নেটওয়ার্ক প্যাটার্ন স্বীকৃতি প্রতিযোগিতায় জয়ী প্রথম আরএনএন ছিল ২০১৪ সালে, চীনা অনুসন্ধান জায়ান্ট বাইদু কোনও ঐতিহ্যবাহী স্পিচ পদ্ধতি ব্যবহার না করে স্যুইচবোর্ড হাব৫'০০ স্পিচ স্বীকৃতি বেঞ্চমার্ক ভাঙতে আরএনএন ব্যবহার করেছিল। এলএসটিএম বৃহত্তর ভোকাবুলারি বক্তৃতা স্বীকৃতি এবং সংশ্লেষকেও উন্নত করেছে এবং গুগল অ্যান্ড্রয়েডে এটি ব্যবহৃত হয়েছিল ২০১৫ সালে গুগলের বক্তৃতা স্বীকৃতিটি এলএসটিএম এর মাধ্যমে 49% উদ্ধৃতি আবশ্যক নাটকীয় পারফরম্যান্স লাফের অভিজ্ঞতা অর্জন করেছে, যা গুগল ভয়েস অনুসন্ধান দ্বারা ব্যবহৃত হয়েছিল। এলএসটিএম উন্নত মেশিন অনুবাদ, ভাষা মডেলিং এবং বহুভাষিক ভাষা প্রক্রিয়াকরণের জন্য রেকর্ডগুলি ভেঙেছে কনভোলিউশনাল নিউরাল নেটওয়ার্কগুলির (সিএনএন) সাথে মিলিত এলএসটিএম স্বয়ংক্রিয় চিত্রের ক্যাপশনে উন্নতি করেছে == স্থাপত্য == আরএনএন বিভিন্ন রূপে আসে। === সম্পূর্ণ পুনরাবৃত্তি === বেসিক আরএনএনগুলি হ'ল নিউরন জাতীয় নোডগুলির একটি ক্রমাগত "স্তরগুলি" হিসাবে সংগঠিত। প্রদত্ত স্তরের প্রতিটি নোড পরের ধারাবাহিক স্তরের প্রতিটি অন্য নোডের সাথে নির্দেশিত (একমুখী) সংযোগের সাথে সংযুক্ত থাকে প্রতিটি নোড (নিউরন) একটি সময়ের পরিবর্তিত বাস্তব-মূল্যবান অ্যাক্টিভেশন থাকে। প্রতিটি সংযোগ একটি পরিবর্তনযোগ্য বাস্তব-মূল্যবান ওজন আছে। নোডগুলি হয় ইনপুট নোড (নেটওয়ার্কের বাইরের থেকে ডেটা গ্রহণ করা), আউটপুট নোড (ফলন ফলাফল), বা লুকানো নোড (যা ইনপুট থেকে আউটপুট পর্যন্ত ডেটা পরিবর্তন করে)। পৃথক সময় সেটিংসে তদারকি করা শিক্ষার জন্য, সত্য-মূল্যবান ইনপুট ভেক্টরগুলির ক্রমগুলি ইনপুট নোডগুলিতে আসে, একবারে একটি ভেক্টর। যে কোনও সময় পদক্ষেপে, প্রতিটি নন-ইনপুট ইউনিট তার বর্তমান অ্যাক্টিভেশন (ফলাফল) এর সাথে সংযুক্ত যে সমস্ত ইউনিটগুলির সক্রিয়করণের ওজনযুক্ত যোগফলের একটি অফলাইন ফাংশন হিসাবে গণনা করে। লক্ষ্য সক্রিয়করণগুলি নির্দিষ্ট সময় ধাপে কিছু আউটপুট ইউনিটের জন্য সরবরাহ করা যেতে পারে। উদাহরণস্বরূপ, যদি ইনপুট সিকোয়েন্সটি কোনও কথ্য অঙ্কের সাথে সম্পর্কিত একটি স্পিচ সিগন্যাল হয় তবে অনুক্রমের শেষে চূড়ান্ত লক্ষ্য আউটপুটটি অঙ্কটিকে একটি লেবেল হতে পারে। শক্তিবৃদ্ধি শেখার সেটিংসে কোনও শিক্ষক লক্ষ্য সংকেত সরবরাহ করে না। পরিবর্তে একটি ফিটনেস ফাংশন বা পুরষ্কার ফাংশন মাঝেমধ্যে আরএনএন এর কার্যকারিতা মূল্যায়নের জন্য ব্যবহৃত হয়, যা পরিবেশকে প্রভাবিত করে এমন অ্যাকুয়েটরের সাথে সংযুক্ত আউটপুট ইউনিটের মাধ্যমে এর ইনপুট প্রবাহকে প্রভাবিত করে। এটি এমন একটি গেম খেলতে ব্যবহৃত হতে পারে যেখানে জিতে থাকা পয়েন্টের সংখ্যার সাথে অগ্রগতি পরিমাপ করা হয়। প্রতিটি ক্রম নেটওয়ার্ক দ্বারা গণনা করা সম্পর্কিত ক্রিয়াকলাপ থেকে সমস্ত লক্ষ্য সংকেতগুলির বিচ্যুতির যোগ হিসাবে ত্রুটি তৈরি করে। অসংখ্য সিকোয়েন্সের প্রশিক্ষণের জন্য, মোট ত্রুটি হ'ল সমস্ত স্বতন্ত্র ক্রমের ত্রুটির যোগফল। === এলমান নেটওয়ার্ক এবং জর্ডান নেটওয়ার্ক === এলম্যান নেটওয়ার্ক হ'ল একটি কনটেক্সট ইউনিট এর সংযোজন সহ একটি তিন-স্তর নেটওয়ার্ক (চিত্রের মধ্যে x, y, এবং হিসাবে অনুভূমিকভাবে সাজানো)। মাঝের (লুকানো) স্তরটি একটি ওজন সহ স্থিরীকৃত এই প্রসঙ্গ ইউনিটের সাথে সংযুক্ত। প্রতিটি সময় পদক্ষেপে, ইনপুটটি সামনে খাওয়ানো হয় এবং একটি শেখার নিয়ম প্রয়োগ করা হয়। ফিক্সড প্রসঙ্গ ইউনিটগুলিতে লুকানো ইউনিটগুলির পূর্ববর্তী মানগুলির একটি অনুলিপি সংরক্ষণ করে (যেহেতু তারা শেখার নিয়ম প্রয়োগ করার আগে সংযোগগুলির উপরে প্রচার করে)। সুতরাং নেটওয়ার্কটি এক ধরনের রাজ্য বজায় রাখতে পারে, যাতে এটি হিসাবে এমন কাজগুলি সম্পাদন করতে দেয় যা একটি স্ট্যান্ডার্ড মাল্টিলেয়ার পারসেপ্ট্রনের ক্ষমতার বাইরে। জর্ডান নেটওয়ার্কগুলি এলমান নেটওয়ার্কগুলির মতো। প্রসঙ্গ ইউনিটগুলি আড়াল স্তরের পরিবর্তে আউটপুট স্তর থেকে খাওয়ানো হয়। জর্দান নেটওয়ার্কে প্রসঙ্গ ইউনিটগুলিকে রাষ্ট্র স্তর হিসাবেও চিহ্নিত করা হয়। তাদের নিজেদের সাথে পুনরাবৃত্তি সংযোগ রয়েছে এলমান এবং জর্দান নেটওয়ার্কগুলি "সাধারণ পুনরাবৃত্ত নেটওয়ার্ক" (এসআরএন) হিসাবেও পরিচিত৷ === হপফিল্ড === হপফিল্ড নেটওয়ার্কটি একটি আরএনএন, যাতে সমস্ত সংযোগগুলি প্রতিসম হয়। এটির জন্য স্থির ইনপুট প্রয়োজন এবং এটি সাধারণ আরএনএন নয়, কারণ এটি নিদর্শনগুলির ক্রমগুলি প্রক্রিয়া করে না। এটি গ্যারান্টি দেয় যে এটি রূপান্তর করবে। যদি সংযোগগুলি হিব্বীয় লার্নিং ব্যবহার করে প্রশিক্ষিত হয় তবে হপফিল্ড নেটওয়ার্ক শক্তিশালী মেমরি হিসাবে সঞ্চালন করতে পারে, সংযোগ পরিবর্তনের বিরুদ্ধে প্রতিরোধী। === দ্বি নির্দেশমূলক সহযোগী মেমরি === বার্ট কোসকো দ্বারা পরিচিত, একটি দ্বিদ্বিধায়ক এসোসিয়েটিভ মেমরি (বিএএম) নেটওয়ার্ক হপফিল্ড নেটওয়ার্কের একটি রূপ যা ভেক্টর হিসাবে এসোসিয়েটিভ ডেটা সঞ্চয় করে। ম্যাট্রিক্স এবং এর ট্রান্সপোজের মাধ্যমে তথ্য পাস করার মাধ্যমে আসে। সাধারণত বাইসোলার এনকোডিংটি সহযোগী জোড়গুলির বাইনারি এনকোডিংয়ের পক্ষে পছন্দ করা হয়। সম্প্রতি, মার্কভ স্টেপিং ব্যবহার করে স্টোকাস্টিক বিএএম মডেলগুলি নেটওয়ার্কের স্থিতিশীলতা এবং সাথে প্রাসঙ্গিকতার জন্য অনুকূলিত হয়েছিল একটি বিএএম নেটওয়ার্কের দুটি স্তর রয়েছে, যার মধ্যে দুটিই কোনও সংস্থাটিকে পুনরায় স্মরণ করতে এবং অন্য স্তরে আউটপুট উত্পাদন করতে ইনপুট হিসাবে চালিত হতে পারে === প্রতিধ্বনি অবস্থা === ইকো স্টেট নেটওয়ার্ক (ইএসএন) এর একটি খুব কম সংযুক্ত বিশৃঙ্খল লুকানো স্তর রয়েছে আউটপুট নিউরনের ওজন হ'ল নেটওয়ার্কের একমাত্র অংশ যা পরিবর্তন করতে পারে (প্রশিক্ষিত হতে পারে)। ইএসএন গুলি নির্দিষ্ট সময় সিরিজের পুনরুত্পাদন করতে ভাল। স্পাইকিং নিউরনগুলির একটি বৈকল্পিক তরল স্টেট মেশিন হিসাবে পরিচিত === স্বতন্ত্র আরএনএন (ইন্ডআরএনএন) === স্বতন্ত্রভাবে পুনরাবৃত্ত নিউরাল নেটওয়ার্ক (ইন্ডআরএনএন) ঐতিহ্যবাহী সম্পূর্ণরূপে সংযুক্ত আরএনএন-তে গ্রেডিয়েন্ট বিলুপ্ত এবং বিস্ফোরিত সমস্যাগুলিকে সম্বোধন করে। এক স্তরের প্রতিটি নিউরন কেবল প্রসঙ্গ তথ্য হিসাবে তার নিজস্ব অতীত অবস্থা গ্রহণ করে (এই স্তরের অন্যান্য সমস্ত নিউরনের সাথে সম্পূর্ণ সংযোগের পরিবর্তে) এবং এইভাবে নিউরন একে অপরের ইতিহাস থেকে স্বাধীন দীর্ঘ বা স্বল্পমেয়াদী স্মৃতিশক্তি রাখার জন্য গ্রেডিয়েন্ট ব্যাকপ্রোপেশনটি গ্রেডিয়েন্ট নিখোঁজ হওয়া এবং বিস্ফোরিত হওয়া এড়াতে নিয়ন্ত্রিত হতে পারে। ক্রস-নিউরন তথ্য পরবর্তী স্তরগুলিতে অন্বেষণ করা হয়। ইন্ডআরএনএনকে রি-ল-র মতো নন-স্যাচুরেটেড ননলাইনার ফাংশনগুলির সাথে শক্তভাবে প্রশিক্ষণ দেওয়া যেতে পারে। এড়িয়ে যাওয়া সংযোগগুলি ব্যবহার করে গভীর নেটওয়ার্কগুলি প্রশিক্ষণ দেওয়া যেতে পারে। === রিকার্সিভ === টপোলজিকাল ক্রম অনুসারে কাঠামোটিকে অনুসরণ করে ডিফারেন্সিয়াল গ্রাফের মতো কাঠামোর উপরে পুনরাবৃত্তভাবে একই ওজনগুলির সেট প্রয়োগ করে একটি পুনরাবৃত্তাকার নিউরাল নেটওয়ার্ক তৈরি করা হয়। এই জাতীয় নেটওয়ার্কগুলি সাধারণত স্বয়ংক্রিয় পার্থক্যের বিপরীত মোড দ্বারাও প্রশিক্ষিত হয় তারা কাঠামোর বিতরণ উপস্থাপনা যেমন যৌক্তিক পদগুলিতে প্রক্রিয়া করতে পারে। রিকার্সিভ নিউরাল নেটওয়ার্কগুলির একটি বিশেষ কেস হল আরএনএন যার কাঠামোটি একটি রৈখিক শৃঙ্খলার সাথে মিলে যায়। প্রাকৃতিক ভাষা প্রক্রিয়াকরণে পুনরাবৃত্তাকার নিউরাল নেটওয়ার্কগুলি প্রয়োগ করা হয়েছে রিকার্সিভ নিউরাল টেনসর নেটওয়ার্ক গাছের সমস্ত নোডের জন্য একটি সেন্সর-ভিত্তিক রচনা ফাংশন ব্যবহার করে === নিউরাল ইতিহাস সংকোচকারী === নিউরাল হিস্ট্রি সংক্ষিপ্তকারীটি আরএনএনগুলির একটি অপ্রচলিত স্ট্যাক ইনপুট স্তরে, এটি পূর্ববর্তী ইনপুটগুলি থেকে এর পরবর্তী ইনপুটটির পূর্বাভাস দিতে শেখে। শ্রেণিবিন্যাসের কিছু আরএনএন কেবলমাত্র অনির্দেশ্য ইনপুটগুলি পরবর্তী উচ্চ স্তরের আরএনএন-এর ইনপুট হয়ে যায়, যার ফলে কেবলমাত্র তার অভ্যন্তরীণ অবস্থার সংশোধন খুব কমই হয়। প্রতিটি উচ্চ স্তরের আরএনএন নীচে আরএনএন-তে তথ্যের সংকীর্ণ উপস্থাপনাটি অধ্যয়ন করে। এটি এমনভাবে করা হয়েছে যে সর্বোচ্চ স্তরের উপস্থাপনা থেকে ইনপুট ক্রমটি সুনির্দিষ্টভাবে পুনর্গঠন করা যায়। সিস্টেমটি কার্যকরভাবে বর্ণনার দৈর্ঘ্য বা উপাত্তের সম্ভাবনার নেতিবাচক লগারিদমকে হ্রাস করে আগত ডেটা সিকোয়েন্সে প্রচুর শেখার পূর্বাভাস দেওয়া, উচ্চ স্তরের আরএনএন তত্ত্বাবধানে থাকা শিক্ষাকে সহজেই গুরুত্বপূর্ণ ইভেন্টগুলির মধ্যে দীর্ঘ বিরতির সাথে আরও গভীর শ্রেণিবদ্ধ করতে ব্যবহার করতে পারে। আরএনএন অনুক্রমকে দুটি আরএনএন-তে বিচ্ছিন্ন করা সম্ভব: "সচেতন" চুনকার (উচ্চ স্তর) এবং "অবচেতন" স্বয়ংচালিত (নিম্ন স্তর) একবার চুনকার অটোম্যাটাইজারের দ্বারা অনুমানযোগ্য ইনপুটগুলির পূর্বাভাস এবং সংকোচন করতে শিখলে, পরবর্তী শিখার পর্যায়ে আরও ধীরে ধীরে পরিবর্তিত চুনকারের গোপন ইউনিটগুলির অতিরিক্ত ইউনিটগুলির মাধ্যমে ভবিষ্যদ্বাণী বা অনুকরণ করতে বাধ্য হতে পারে। এটি উপযুক্ত শিখতে সহজ করে তোলে, দীর্ঘ বিরতিতে খুব কমই স্মৃতি পরিবর্তন করে। ঘুরেফিরে এটি অটোম্যাটাইজারকে তার এককালের অপ্রত্যাশিত ইনপুটগুলিকে করে তুলতে সহায়তা করে, যেমন চুনকারটি বাকি অপ্রত্যাশিত ইভেন্টগুলিতে মনোনিবেশ করতে পারে একটি জেনারেটাল মডেল ১৯৯২ সালে নিউরাল স্বয়ংক্রিয় পার্থক্য বা ব্যাকপ্রোপাগেশন অদৃশ্য হয়ে যাওয়া গ্রেডিয়েন্ট সমস্যা আংশিকভাবে কাটিয়ে উঠেছে === দ্বিতীয় আদেশ আরএনএন === দ্বিতীয় অর্ডার আরএনএনগুলি ওজনগুলির পরিবর্তে উচ্চতর অর্ডার ওয়েট ব্যবহার করে এবং অবস্থাগুলি একটি পণ্য হতে পারে। এটি প্রশিক্ষণ, স্থায়িত্ব এবং প্রতিনিধিত্ব উভয় ক্ষেত্রেই সীমাবদ্ধ রাষ্ট্রের মেশিনে সরাসরি ম্যাপিংয়ের অনুমতি দেয় দীর্ঘ স্বল্পমেয়াদী মেমরির এটি একটি উদাহরণ তবে এর মধ্যে কোনও আনুষ্ঠানিক ম্যাপিং বা স্থিতির প্রমাণ নেই। === দীর্ঘ স্বল্পমেয়াদী স্মৃতি === দীর্ঘ স্বল্প-মেয়াদী মেমরি (এলএসটিএম) একটি গভীর শিক্ষার ব্যবস্থা যা বিলুপ্ত গ্রেডিয়েন্ট সমস্যাটিকে এড়িয়ে চলে। এলএসটিএম সাধারণত "ভুলে যান" গেটস নামে পুনরাবৃত্ত গেটগুলির সাহায্যে বাড়ানো হয় এলএসটিএম ব্যাকপ্রেজিটেড ত্রুটিগুলি বিলুপ্ত বা বিস্ফোরিত হওয়া থেকে রোধ করে পরিবর্তে, ত্রুটিগুলি স্থান সীমাহীন ভার্চুয়াল স্তরগুলির সীমাহীন সংখ্যার মাধ্যমে পিছনের দিকে প্রবাহিত হতে পারে। এটি হ'ল, এলএসটিএম এমন কাজগুলি শিখতে পারে যা ঘটনার স্মৃতিগুলির প্রয়োজন যা হাজার হাজার বা এমনকি কয়েক মিলিয়ন স্বতন্ত্র সময়ের পদক্ষেপগুলির আগে হয়েছিল। এলএসটিএম-জাতীয় টপোলজগুলি বিবর্তিত হতে পারে এলএসটিএম এমনকি উল্লেখযোগ্য ইভেন্টগুলির মধ্যে দীর্ঘ বিলম্বের জন্যও কাজ করে এবং কম এবং উচ্চ ফ্রিকোয়েন্সি উপাদানগুলিকে মিশ্রিত সংকেতগুলি পরিচালনা করতে পারে। অনেক অ্যাপ্লিকেশন এলএসটিএম আরএনএনগুলির স্ট্যাক ব্যবহার করে এবং সংযোগবাদী টেম্পোরাল শ্রেণিবিন্যাস (সিটিসি) দ্বারা প্রশিক্ষণ দেয় একটি আরএনএন ওজন ম্যাট্রিক্স অনুসন্ধান করার জন্য যা সংশ্লিষ্ট ইনপুট সিকোয়েন্সগুলি দেখিয়ে একটি প্রশিক্ষণ সেটে লেবেলের সিকোয়েন্সগুলির সম্ভাবনা সর্বাধিক করে তোলে। সিটিসি প্রান্তিককরণ এবং স্বীকৃতি উভয়ই অর্জন করে। এলএসটিএম লুকানো মার্কভ মডেল (এইচএমএম) এবং অনুরূপ ধারণার উপর ভিত্তি করে পূর্ববর্তী মডেলের বিপরীতে ভাষাগুলি সনাক্ত করতে শিখতে পারে === গেটেড পুনরাবৃত্তি ইউনিট === গেটেড পুনরাবৃত্ত ইউনিট (জিআরইউ) ২০১৪ সালে চালু হওয়া পুনরাবৃত্ত নিউরাল নেটওয়ার্কগুলির একটি গেটিং মেকানিজম এগুলি পুরো ফর্ম এবং বেশ কয়েকটি সরলিকৃত রূপগুলিতে ব্যবহৃত হয় পলিফোনিক মিউজিক মডেলিং এবং স্পিচ সিগন্যাল মডেলিংয়ে তাদের অভিনয় দীর্ঘ স্বল্পমেয়াদী মেমরির মতো দেখা যায় তাদের কাছে এলএসটিএম এর চেয়ে কম পরামিতি রয়েছে কারণ তাদের আউটপুট গেটের অভাব রয়েছে === দ্বি-মুখী === আরএনএনগুলি উপাদানটির অতীত এবং ভবিষ্যতের প্রেক্ষাপটের উপর ভিত্তি করে ক্রমের প্রতিটি উপাদানকে ভবিষ্যদ্বাণী বা লেবেল করতে সীমাবদ্ধ ক্রম ব্যবহার করে। এটি দুটি আরএনএনগুলির আউটপুটগুলি সংক্ষিপ্ত করে তৈরি করা হয়, একটি ক্রমটি বাম থেকে ডানে, অন্যটি ডান থেকে বামে প্রক্রিয়াকরণ করে। সম্মিলিত ফলাফলগুলি শিক্ষক প্রদত্ত লক্ষ্য সংকেতগুলির পূর্বাভাস। এলএসটিএম আরএনএনগুলির সাথে একত্রিত হয়ে এই কৌশলটি বিশেষভাবে কার্যকর হিসাবে প্রমাণিত হয়েছিল === ক্রমাগত টাইম === একটি অবিচ্ছিন্ন সময় পুনরাবৃত্ত নিউরাল নেটওয়ার্ক (সিটিআরএনএন) ইনকামিং স্পাইক ট্রেনের নিউরনের উপর প্রভাবগুলি মডেল করতে সাধারণ ডিফারেনশিয়াল সমীকরণের একটি সিস্টেম ব্যবহার করে। সিটিআরএনএনগুলি বিবর্তনীয় রোবোটিকগুলিতে প্রয়োগ করা হয়েছে যেখানে এটি দৃষ্টি, সহযোগিতা, এবং ন্যূনতম জ্ঞানীয় আচরণের জন্য ব্যবহার করা হয়েছে মনে রাখবেন, শ্যানন স্যাম্পলিং উপপাদ্য দ্বারা, পৃথক সময় পুনরাবৃত্ত নিউরাল নেটওয়ার্কগুলি অবিচ্ছিন্ন সময় পুনরাবৃত্ত নিউরাল নেটওয়ার্ক হিসাবে দেখা যায় যেখানে ডিফারেনশিয়াল সমীকরণগুলি সমতুল্য পার্থক্য সমীকরণে রূপান্তরিত হয়েছে। এই রূপান্তরটি পোস্ট-সিনাপটিক নোড অ্যাক্টিভেশন ফাংশন এর পরে লো-পাস ফিল্টার করা হয়েছে তবে নমুনা দেওয়ার আগে ঘটেছিল বলে মনে করা যেতে পারে। === প্রধান === হায়ারার্কিকাল আরএনএনগুলি হায়ারারিকাল আচরণকে পাতলা করার জন্য বিভিন্ন উপায়ে তাদের নিউরনগুলিকে দরকারী সংযুক্ত করে === পুনরাবৃত্ত মাল্টিলেয়ার পারসেপ্ট্রোন নেটওয়ার্ক === সাধারণত, একটি পুনরাবৃত্তি মাল্টি-লেয়ার পারসেপ্ট্রন (আরএমএলপি) নেটওয়ার্কে ক্যাসকেড সাবনেটওয়ার্ক থাকে, যার প্রতিটিটিতে নোডের একাধিক স্তর থাকে। এই প্রতিটি ফিড-ফরোয়ার্ড শেষ স্তর ব্যতীত, এতে প্রতিক্রিয়া সংযোগ থাকতে পারে। এই সাবনেটগুলির প্রত্যেকটিই কেবল ফিড ফরোয়ার্ড সংযোগের মাধ্যমে সংযুক্ত থাকে === একাধিক টাইমস্কেলস মডেল === একাধিক টাইমসেলস রিরেন্ট নিউরাল নেটওয়ার্ক (এমটিআরএনএন) হ'ল একটি নিউরাল-ভিত্তিক কম্পিউটেশনাল মডেল যা স্ব-সংস্থার মাধ্যমে মস্তিষ্কের ক্রিয়ামূলক শ্রেণিবিন্যাসের অনুকরণ করতে পারে যা নিউরনের মধ্যে এবং পৃথক ধরনের নিউরনের উপর নির্ভর করে, প্রতিটি স্বতন্ত্র সময়ের বৈশিষ্ট্যযুক্ত। জাতীয় বৈচিত্র্যময় নিউরোনাল সাথে, আচরণের কোনও সেটগুলির ক্রমাগত ক্রমগুলি পুনরায় ব্যবহারযোগ্য আদিমগুলিতে বিভক্ত হয়, যার ফলে নমনীয়ভাবে বিভিন্ন অনুক্রমিক আচরণের সাথে সংহত হয়। জাতীয় ধরনের শ্রেণিবিন্যাসের জৈবিক অনুমোদনের বিষয়ে হক্কিনস তার অন ইন্টেলিজেন্স বইয়ে মস্তিষ্কের ক্রিয়া সম্পর্কিত তত্ত্বে আলোচনা করেছিলেন। === নিউরাল ট্যুরিং মেশিন === নিউরাল ট্যুরিং মেশিনগুলি (এনটিএম) হ'ল বহিরাগত মেমরি রিসোর্সে সংযুক্ত করে পুনরাবৃত্ত নিউরাল নেটওয়ার্কগুলি প্রসারিত করার একটি পদ্ধতি যা তারা মনোনিবেশমূলক প্রক্রিয়াগুলির মাধ্যমে ইন্টারেক্ট করতে পারে। সম্মিলিত সিস্টেমটি একটি ট্যুরিং মেশিন বা ভন নিউম্যান আর্কিটেকচারের সাথে সমান, তবে এটি প্রান্ত থেকে শেষ অবধি, এটি গ্রেডিয়েন্ট বংশোদ্ভূত দক্ষতার সাথে প্রশিক্ষণের জন্য অনুমতি দেয় === পার্থক্যযোগ্য নিউরাল কম্পিউটার === ডিফরেনটেটেবল নিউরাল কম্পিউটার (ডিএনসি) হ'ল নিউরাল টুরিং মেশিনগুলির একটি বর্ধিতাংশ, প্রতিটি মেমরি ঠিকানার अस्पष्ट পরিমাণে ব্যবহার করার অনুমতি দেয় এবং কালানুক্রমিক রেকর্ড করে। === নিউরাল নেটওয়ার্ক পুডডাউন অটোমেটা === নিউরাল নেটওয়ার্ক পুশডাউন অটোমেটা (এনএনপিডিএ) এনটিএম এর অনুরূপ, তবে টেপগুলি অ্যানালগ স্ট্যাকগুলি দ্বারা প্রতিস্থাপন করা হয় যা পার্থক্যযোগ্য এবং প্রশিক্ষিত। এইভাবে, তারা প্রসঙ্গ মুক্ত ব্যাকরণ (সিএফজি) এর মতো জটিলতার সাথে সমান। == প্রশিক্ষণ == === গ্রেডিয়েন্ট বংশোদ্ভূত === গ্রেডিয়েন্ট বংশদ্ভুত একটি ফাংশনের সর্বনিম্ন সন্ধানের জন্য একটি প্রথম-ক্রম পুনরাবৃত্তিমূলক অপ্টিমাইজেশন অ্যালগরিদম। নিউরাল এটির ওজনের সাথে সম্পর্কিত ত্রুটির ডেরাইভেটিভের অনুপাতে প্রতিটি ওজন পরিবর্তন করে ত্রুটি শব্দটি হ্রাস করতে ব্যবহার করা যেতে পারে, তবে শর্ত থাকে যে অ-রৈখিক অ্যাক্টিভেশন কর্মটি পৃথকযোগ্য ti এটি করার বিভিন্ন উপায় ১৯৮০ এবং ১৯৯০ এর দশকে ওয়ার্বোস, উইলিয়ামস, রবিনসন, শ্মিধুবার, হোক্রেইটার, পার্লমুটার এবং অন্যান্যরা বিকাশ করেছিলেন। স্ট্যান্ডার্ড পদ্ধতিটিকে "সময়ের মাধ্যমে বা বিপিটিটি বলা হয় এবং এটি ফিড-ফরোয়ার্ড নেটওয়ার্কগুলির জন্য ব্যাক-বর্ধনের একটি সাধারণীকরণ। সেই পদ্ধতির মতো এটি পন্ট্রিয়াগিনের ন্যূনতম নীতিটির বিপরীত সংশ্লেষ মোডে স্বয়ংক্রিয় পার্থক্যের একটি উদাহরণ। আরও গণনামূলকভাবে ব্যয়বহুল অনলাইন ভেরিয়েন্টকে বলা হয় "রিয়েল-টাইম রিকভারেন্ট লার্নিং" বা আরটিআরএল, যা স্ট্যাকড ট্যানজেন্ট ভেক্টরগুলির সাথে ফরোয়ার্ড অ্যাকোমোশন মোডে স্বয়ংক্রিয় পার্থক্যের একটি উদাহরণ। বিপিটিটি-র বিপরীতে, এই অ্যালগরিদমটি সময়মতো স্থানীয় তবে স্থানটিতে স্থানীয় নয়। এই প্রসঙ্গে, স্থানের স্থানীয় মানে হ'ল কোনও ইউনিটের ওজন ভেক্টর কেবল সংযুক্ত ইউনিটগুলিতে সঞ্চিত তথ্য ব্যবহার করে আপডেট করা যেতে পারে এবং ইউনিট নিজেই যেমন একক ইউনিটের আপডেট জটিলতা ওজন ভেক্টরের মাত্রিক ক্ষেত্রে লিনিয়ার। স্থানীয় সময়ে সময় মানে আপডেটগুলি ক্রমাগত (অন-লাইন) হয় এবং বিপিটিটির মতো নির্দিষ্ট সময় দিগন্তের মধ্যে একাধিক সময় পদক্ষেপের চেয়ে কেবল সাম্প্রতিক সময়ের ধাপের উপর নির্ভর করে। জৈবিক নিউরাল নেটওয়ার্কগুলি সময় এবং স্থান উভয়েরই সম্মানের সাথে স্থানীয় বলে মনে হয় আংশিক ডেরাইভেটিভগুলি পুনরাবৃত্তভাবে গণনা করার জন্য, আরটিআরএল-এর জেকোবিয়ান ম্যাট্রিকেস গণনা করার জন্য প্রতি সময় ধাপে (লুকানো এক্স ওজনের সংখ্যার সংখ্যা) এর সময়-জটিলতা রয়েছে, যখন বিপিটিটি ব্যয় অনুসারে শুধুমাত্র প্রতি ধাপে (ওজনের সংখ্যা) নেয় প্রদত্ত সময়ের দিগন্তের মধ্যে সমস্ত ফরোয়ার্ড ক্রিয়াকলাপ সংরক্ষণের মধ্যবর্তী জটিলতার সাথে বিপিটিটি এবং আরটিআরএল-এর মধ্যে একটি অনলাইন হাইব্রিড বিদ্যমান, অবিচ্ছিন্ন সময়ের জন্য রূপগুলি স্ট্যান্ডার্ড আরএনএন আর্কিটেকচারের গ্রেডিয়েন্ট বংশোদ্ভূত হওয়ার একটি বড় সমস্যা হ'ল ত্রুটি গুরুত্বপূর্ণ ইভেন্টগুলির মধ্যে সময়ের ব্যবধানের সাথে দ্রুততার সাথে দ্রুত অদৃশ্য হয়ে যায় এলপিএসএম একটি বিপিটিটি আরটিআরএল সংকর শেখার পদ্ধতির সাথে একত্রিত হয়ে এই সমস্যাগুলি কাটিয়ে উঠার চেষ্টা করে এই সমস্যাটি স্বতন্ত্রভাবে পুনরাবৃত্ত নিউরাল নেটওয়ার্ক (ইন্ডআরএনএন) এও সমাধান করা হয়েছে নিউরনের প্রসঙ্গটি তার নিজস্ব অতীত অবস্থাতে হ্রাস করে এবং ক্রস-নিউরন তথ্যগুলি নিম্নলিখিত স্তরগুলিতে অনুসন্ধান করা যেতে পারে। দীর্ঘমেয়াদী মেমরি সহ বিভিন্ন পরিসরের স্মৃতিগুলি গ্রেডিয়েন্ট নিখোঁজ হওয়া এবং বিস্ফোরিত সমস্যা ছাড়াই শিখতে পারে। অন-লাইন অ্যালগরিদমকে সিআরবিপি বলা হয়, স্থানীয়ভাবে পুনরাবৃত্ত নেটওয়ার্কগুলির জন্য বিপিটিটি এবং আরটিআরএল দৃষ্টান্ত প্রয়োগ করে এবং একত্রিত করে এটি সর্বাধিক সাধারণ স্থানীয়ভাবে পুনরাবৃত্ত নেটওয়ার্কগুলির সাথে কাজ করে। সিআরবিপি অ্যালগরিদম বিশ্বব্যাপী ত্রুটি শব্দটি হ্রাস করতে পারে। এই সত্যটি অ্যালগরিদমের স্থিতিশীলতার উন্নতি করে, স্থানীয় প্রতিক্রিয়া সহ পুনরাবৃত্ত নেটওয়ার্কগুলির জন্য গ্রেডিয়েন্ট গণনা কৌশলগুলিতে একত্রিত দৃষ্টিভঙ্গি সরবরাহ করে। স্বেচ্ছাসেবী আর্কিটেকচার সহ আরএনএনগুলিতে গ্রেডিয়েন্ট তথ্য গণনার এক পদ্ধতির সংকেত-প্রবাহ গ্রাফগুলি ডেরাইভেশন ভিত্তিক এটি নেটওয়ার্ক সংবেদনশীলতা গণনার জন্য লি এর উপপাদ্যের ভিত্তিতে বিপিটিটি ব্যাচ অ্যালগরিদম ব্যবহার করে এটি ওয়ান এবং বিউফেস প্রস্তাব করেছিলেন, এর দ্রুত অনলাইন সংস্করণটি ক্যাম্পলুচি, আনসিনি এবং পিয়াজা প্রস্তাব করেছিলেন। === গ্লোবাল অপ্টিমাইজেশন পদ্ধতি === নিউরাল নেটওয়ার্কে ওজনকে প্রশিক্ষণ দেওয়া একটি অ-রৈখিক গ্লোবাল অপটিমাইজেশন সমস্যা হিসাবে মডেল করা যেতে পারে। কোনও নির্দিষ্ট ওজন ভেক্টরের ফিটনেস বা ত্রুটির মূল্যায়ন করার জন্য একটি লক্ষ্য ফাংশন তৈরি করা যেতে পারে: প্রথমত, নেটওয়ার্কের ওজনগুলি ওয়েট ভেক্টর অনুসারে সেট করা হয়। এর পরে, নেটওয়ার্কটি প্রশিক্ষণ ক্রমের বিপরীতে মূল্যায়ন করা হয়। সাধারণত, অনুমান এবং প্রশিক্ষণের অনুক্রমের মধ্যে নির্দিষ্ট লক্ষ্য মানগুলির মধ্যে যোগফলের পার্থক্যটি বর্তমান ওজন ভেক্টরের ত্রুটির প্রতিনিধিত্ব করতে ব্যবহৃত হয়। এই লক্ষ্য ফাংশনটি হ্রাস করার জন্য নির্বিচারে গ্লোবাল অপ্টিমাইজেশন কৌশলগুলি ব্যবহার করা যেতে পারে। আরএনএন প্রশিক্ষণের জন্য সবচেয়ে সাধারণ গ্লোবাল অপ্টিমাইজেশন পদ্ধতি হ'ল জেনেটিক অ্যালগরিদম, বিশেষত কাঠামোগত প্রাথমিকভাবে, জেনেটিক অ্যালগরিদম একটি পূর্বনির্ধারিত পদ্ধতিতে নিউরাল নেটওয়ার্ক ওয়েটের সাথে এনকোড করা থাকে যেখানে ক্রোমোসোমের একটি জিন একটি ওজন লিঙ্ক উপস্থাপন করে। পুরো নেটওয়ার্কটি একক ক্রোমোজোম হিসাবে উপস্থাপিত হয়। ফিটনেস ফাংশনটি নীচে মূল্যায়ন করা হয়: ক্রোমোসোমে এনকোড করা প্রতিটি ওজন নেটওয়ার্কের সংশ্লিষ্ট ওজন লিঙ্ককে বরাদ্দ করা হয়। প্রশিক্ষণের সেটটি নেটওয়ার্কের সামনে উপস্থাপিত হয় যা ইনপুট সংকেতগুলি এগিয়ে প্রচার করে। গড় স্কোয়ার-ত্রুটি ফিটনেস ফাংশনে ফিরে আসে। এই ফাংশনটি জিনগত নির্বাচন প্রক্রিয়া চালিত করে। অনেক ক্রোমোসোম জনসংখ্যা তৈরি করে; অতএব, একটি স্টপিং মানদণ্ডটি সন্তুষ্ট না হওয়া পর্যন্ত অনেকগুলি বিভিন্ন স্নায়ু নেটওয়ার্ক বিবর্তিত হয়। একটি সাধারণ স্টপিং স্কিমটি হ'ল: যখন নিউরাল নেটওয়ার্ক প্রশিক্ষণের ডেটা বা একটি নির্দিষ্ট শতাংশ শিখেছে যখন সর্বনিম্ন মান সন্তুষ্ট হয় বা হয় যখন প্রশিক্ষণের প্রজন্মের সর্বাধিক সংখ্যা পৌঁছে গেছে থামানোর মানদণ্ডটি ফিটনেস ফাংশন দ্বারা মূল্যায়ন করা হয় কারণ এটি প্রশিক্ষণের সময় প্রতিটি নেটওয়ার্ক থেকে প্রতিদান পায়। সুতরাং, জেনেটিক অ্যালগরিদমের লক্ষ্য হ'ল হ্রাস করে ফিটনেস ফাংশনকে সর্বাধিক করে তোলা। অন্যান্য গ্লোবাল (এবং বা বিবর্তনমূলক) অপ্টিমাইজেশান কৌশলগুলি ভাল ওজনের একটি ভাল সেট যেমন সিমুলেটেড অ্যানিলিং বা কণা ঝাঁক অপ্টিমাইজেশন ব্যবহার করতে ব্যবহৃত হতে পারে। == সম্পর্কিত ক্ষেত্র এবং মডেল == আরএনএনগুলি বিশৃঙ্খলভাবে আচরণ করতে পারে। এই জাতীয় ক্ষেত্রে, গতিশীল সিস্টেম তত্ত্ব বিশ্লেষণের জন্য ব্যবহার করা যেতে পারে। এগুলি আসলে একটি নির্দিষ্ট কাঠামোর সাথে পুনরাবৃত্তকারী নিউরাল নেটওয়ার্ক: লিনিয়ার চেইনের। যখন পুনরাবৃত্তাকার নিউরাল নেটওয়ার্কগুলি যে কোনও শ্রেণিবিন্যাসের কাঠামোতে কাজ করে, বাচ্চাদের প্রতিনিধিত্বকে পিতামাতার উপস্থাপনার সাথে সংযুক্ত করে, পুনরাবৃত্ত নিউরাল নেটওয়ার্কগুলি সময়ের রৈখিক অগ্রগতিতে কাজ করে, পূর্ববর্তী সময়ের ধাপ এবং বর্তমান সময়ের পদক্ষেপের জন্য উপস্থাপনার মধ্যে একটি লুকানো প্রতিনিধিত্বকে একত্রিত করে। বিশেষত, আরএনএনস সীমাবদ্ধ ইমপালস প্রতিক্রিয়া এবং অসীম প্রেরণা প্রতিক্রিয়া ফিল্টারগুলির ননলাইন সংস্করণ এবং একটি ননলাইনার অটোরেগ্রেসিভ বহির্মুখী মডেল (এনএআরএক্স) হিসাবে উপস্থিত হতে পারে == লাইব্রেরি == আপাচে সিংগা ক্যাফে: বার্কলে ভিশন অ্যান্ড লার্নিং সেন্টার (বিভিএলসি) দ্বারা নির্মিত। এটি সিপিইউ এবং জিপিইউ উভয়ই সমর্থন করে। সি ++ বিকাশ হয়েছে এবং এতে পাইথন এবং এমএটিএলবি র‌্যাপ রয়েছে। চেইনার: প্রথম স্থিতিশীল গভীর লার্নিং লাইব্রেরি যা গতিশীল, সংজ্ঞা দ্বারা চালিত নিউরাল সমর্থন করে। সম্পূর্ণ পাইথনে, সিপিইউ, জিপিইউ-র জন্য উত্পাদন সমর্থন বিতরণ প্রশিক্ষণ। ডিপলাইনিং জে: স্পার্কে জাভা এবং স্কালায় গভীর শিক্ষা। সিভি ++ বৈজ্ঞানিক কম্পিউটিং ইঞ্জিনে চলমান জেভিএম উত্পাদন স্ট্যাকের জন্য একটি সাধারণ-উদ্দেশ্য গভীর শিক্ষা গ্রন্থাগার। কাস্টম স্তর তৈরির অনুমতি দেয়। হাদোপ এবং কাফকার সাথে একীভূত হয়। ডায়নেট: ডায়নামিক নিউরাল নেটওয়ার্কস সরঞ্জামদণ্ড। ফ্লাক্স: জুলিয়ায় লিখিত জিআরইউ এবং এলএসটিএম সহ আরএনএনগুলির জন্য ইনফেরফেস অন্তর্ভুক্ত করে। কেরাস: উচ্চ-স্তরের, এপিআই ব্যবহার করা সহজ, আরও অনেক গভীর শিখন লাইব্রেরিতে একটি মোড়ক সরবরাহ করে। মাইক্রোসফ্ট কগনিটিভ টুলকিট এমএক্সনেট: গভীর স্নায়ুবিক নেটওয়ার্ক প্রশিক্ষণ এবং স্থাপনের জন্য ব্যবহৃত একটি আধুনিক ওপেন সোর্স গভীর শেখার কাঠামো। পাইটর্চ: শক্তিশালী জিপিইউ ত্বরণ সহ পাইথনের টেনেসর এবং গতিশীল নিউরাল নেটওয়ার্ক। টেনসরফ্লো: সিপিইউ, জিপিইউ এবং গুগলের মালিকানাধীন টিপিইউ,মোবাইলের সহায়তায় অ্যাপাচি থায়ানো-মতো লাইব্রেরি থিয়ানো: জনপ্রিয় নুমপি লাইব্রেরির সাথে মূলত সুসংগত একটি এপিআই সহ পাইথনের রেফারেন্স ডিপ-লার্নিং লাইব্রেরি। ব্যবহারকারীকে প্রতীকী গাণিতিক অভিব্যক্তি লেখার অনুমতি দেয়, তারপরে তাদের ডেরাইভেটিভগুলি উত্পন্ন করে, ব্যবহারকারীকে কোড গ্রেডিয়েন্ট বা ব্যাকপ্রোপেশন থেকে রক্ষা করে। এই প্রতীকী অভিব্যক্তিগুলি জিপিইউ-র প্রয়োগের জন্য সিইউডিএ কোডে সংকলিত হয়। == অ্যাপ্লিকেশন == পুনরাবৃত্ত নিউরাল নেটওয়ার্কগুলির প্রয়োগগুলির মধ্যে রয়েছে: যন্ত্রানুবাদ রোবট নিয়ন্ত্রণ সময় সিরিজের পূর্বাভাস স্পিচ স্বীকৃতি স্পিচ সংশ্লেষণ সময় সিরিজ অসাধারণ সনাক্তকরণ ছন্দ শেখা সংগীত রচনা ব্যাকরণ শেখা হস্তাক্ষর স্বীকৃতি মানুষের ক্রিয়া স্বীকৃতি প্রোটিন হোমোলজি সনাক্তকরণ প্রোটিনের উপকোষীয় স্থানীয়করণের পূর্বাভাস ব্যবসায়িক প্রক্রিয়া পরিচালনার ক্ষেত্রে বিভিন্ন পূর্বাভাসের কাজ চিকিত্সা যত্নের পথে ভবিষ্যদ্বাণী